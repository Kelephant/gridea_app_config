{
  "posts": [
    {
      "content": "在项目开发过程中，我们常常需要定时的执行一些任务，通常的做法我们会创建一个线程，然后在线程里执行一个定时任务，如果有N个定时任务，则需要启动N个定时任务。这种做法有以下几个弊端。\r\n1、频繁的创建线程可能会影响系统的整体运作性能。\r\n2、每实现一个定时任务，则需要考虑任务的创建，销毁，任务的执行，而且大部分的内容是冗余的。\r\n3、多任务之间的同步问题。\r\n为了解决以上问题，我实现了一个多实例单线程多任务的定时器库。\r\n\r\n<!-- more -->\r\n\r\n# 实现方案\r\n## 数据结构\r\n ```\r\ntypedef struct {\r\n    struct list_head       head;                    // 链表头\r\n    mtimer_task_callback   run;                     // 任务回调\r\n    unsigned int        id;                         // 定时任务id\r\n    unsigned int        last_tick;                  // 上一次执行的时间\r\n    unsigned int        timeout;                    // 定时的超时时间，ms\r\n    mtimer_task_mode    mode;                       // 定时任务的工作模式，两种工作模式。\r\n    void           *user_data1;                     // 定时任务的上下文1\r\n    void           *user_data2;                     // 定时任务的上下文2\r\n    unsigned int        remove;                     // 定时任务是否标记删除\r\n} mtimer_task;                                      // 定时任务节点\r\n \r\ntypedef struct {\r\n    struct list_head    list;                       // 任务列表\r\n    pthread_mutex_t  lock;                          // 锁\r\n    unsigned int            id;                     // 待分配的定时器任务id\r\n    mtimer_get_current_time get_current_time;       // 获取ms值的接口\r\n} mtimer_handle;                                    // 定时器实例\r\n ```\r\n\r\n## 工作模式\r\n### 定时器有两种工作模式\r\n ```\r\ntypedef enum {\r\n    MTIMER_MODE_LOOP = 0,        // 循环任务，每隔一个timeout执行一次\r\n    MTIMER_MODE_NOT_LOOP,        // 非循环任务，仅在timeout时执行一次\r\n} mtimer_task_mode;\r\n ```\r\n## 接口\r\n ```\r\n/*****************************************************************************\r\n 函 数 名  : mtimer_create\r\n 功能描述  : 创建定时器库实例\r\n 输入参数  : mtimer_get_current_time func  \r\n 输出参数  : 无\r\n 返 回 值  : void\r\n            NULL    : 创建失败\r\n            非NULL   : 创建成功\r\n*****************************************************************************/\r\nvoid *mtimer_create(mtimer_get_current_time func);\r\n \r\n/*****************************************************************************\r\n 函 数 名  : mtimer_destroy\r\n 功能描述  : 销毁定时器库实例\r\n 输入参数  : void *handle  \r\n 输出参数  : 无\r\n 返 回 值  : int\r\n            0   成功\r\n            <0  失败\r\n*****************************************************************************/\r\nint mtimer_destroy(void *handle);\r\n \r\n/*****************************************************************************\r\n 函 数 名  : mtimer_task_reg\r\n 功能描述  : 注册定时器任务\r\n 输入参数  : void *handle                 \r\n             mtimer_task_callback run  任务回调\r\n             unsigned int    timeout   超时时间\r\n             mtimer_task_mode    mode  LOOP:循环, 每隔timeout触发一次; NOT_LOOP:仅运行一次\r\n             void       *user_data1    回调参数1\r\n             void       *user_data2    回调参数2\r\n 输出参数  : 无\r\n 返 回 值  : unsigned\r\n            返回定时器id\r\n*****************************************************************************/\r\nunsigned int mtimer_task_reg(\r\n    void *handle,\r\n    mtimer_task_callback run,\r\n    unsigned int    timeout,\r\n    mtimer_task_mode    mode,\r\n    void       *user_data1,\r\n    void       *user_data2);\r\n \r\n/*****************************************************************************\r\n 函 数 名  : mtimer_task_unreg\r\n 功能描述  : 反注册定时器任务\r\n 输入参数  : void *handle          \r\n             unsigned int task_id   定时任务id  \r\n 输出参数  : 无\r\n 返 回 值  : 0: 反注册成功\r\n            <0: 反注册失败\r\n*****************************************************************************/\r\nint mtimer_task_unreg(void *handle, unsigned int task_id);\r\n \r\n/*****************************************************************************\r\n 函 数 名  : mtimer_schedule\r\n 功能描述  : 定时任务调度\r\n 输入参数  : void *handle    \r\n             unsigned int n  最多可执行的定时任务数，防止线程阻塞太长时间\r\n 输出参数  : 无\r\n 返 回 值  : 0  执行正常\r\n            <0  执行异常\r\n*****************************************************************************/\r\nint mtimer_schedule(void *handle, unsigned int n);\r\n ```\r\n### 使用范例\r\n ```\r\nint func1(void *data1, void *data2)\r\n{\r\n    log_error(\"[time:%u, func1], data1:%s, data2:%s\\n\", Clock_GetTimeMs(),\r\n              (char *)data1, (char *)data2);\r\n    return 0;\r\n}\r\n \r\nint func2(void *data1, void *data2)\r\n{\r\n    log_error(\"[time:%u, func2], data1:%s, data2:%s\\n\", Clock_GetTimeMs(),\r\n              (char *)data1, (char *)data2);\r\n    return 0;\r\n}\r\n \r\nvoid *mtimer_debug_loop(void *handle)\r\n{\r\n \r\n    unsigned id1, id2;\r\n \r\n    log_error(\"tick: %u------------------------------------ 1\\n\\n\",\r\n              Clock_GetTimeMs());\r\n    id1 = mtimer_task_reg(handle, func1, 500, MTIMER_MODE_LOOP, \"1data1\", \"1data2\");\r\n    id2 = mtimer_task_reg(handle, func2, 1000, MTIMER_MODE_NOT_LOOP, \"2data1\",\r\n                          \"2data2\");\r\n    while (1) {\r\n        mtimer_schedule(handle, 10);\r\n        Clock_SleepMs(100);\r\n    }\r\n \r\n    mtimer_destroy(handle);\r\n \r\n    return NULL;\r\n}\r\n \r\nint mtimer_debug()\r\n{\r\n    void *handle;\r\n    if (IS_NULL(handle = mtimer_create(Clock_GetTimeMs))) {\r\n        log_error(\"mtimer_create failed\\n\");\r\n        return -1;\r\n    }\r\n \r\n    pthread_t tid;\r\n    pthread_create(&tid, NULL, mtimer_debug_loop, (void *)handle);\r\n    pthread_detach(tid);\r\n \r\n    return 0;\r\n}\r\n ```\r\n\r\n# 完整代码\r\n代码还没有整理好，后续整理完之后会有更新，迫切需要的可以私聊\r\n",
      "data": {
        "title": "C语言定时任务库的实现（一）",
        "date": "2024-04-10 15:13:14",
        "tags": [
          "timer",
          "C"
        ],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "在项目开发过程中，我们常常需要定时的执行一些任务，通常的做法我们会创建一个线程，然后在线程里执行一个定时任务，如果有N个定时任务，则需要启动N个定时任务。这种做法有以下几个弊端。\r\n1、频繁的创建线程可能会影响系统的整体运作性能。\r\n2、每实现一个定时任务，则需要考虑任务的创建，销毁，任务的执行，而且大部分的内容是冗余的。\r\n3、多任务之间的同步问题。\r\n为了解决以上问题，我实现了一个多实例单线程多任务的定时器库。\r",
      "fileName": "c-yu-yan-ding-shi-ren-wu-ku-de-shi-xian-yi"
    },
    {
      "content": "Openbmc ipmi在运行之后，出现段错误\r\n<!-- more -->\r\n\r\n# 背景\r\n\r\nOpenbmc ipmi在运行之后，出现段错误，段错误的dump信息如下\r\n\r\n通过堆栈可以看到异常在openssl库里面，再往上追踪已经没有栈了\r\n\r\n# 分析\r\n\r\nOpenssl库正常是不会有问题的，可以先暂时先排除。再往上就是栈被破坏了，谁调用EVP_Q_mac不知道，分析到这里就懒得再往下追踪了。后续通过替换openbmc版本，ipmi版本尝试解决，做了很多无用功。最面，通过分析github上的log才找到真正的问题。如果当初硬着头皮，往下想想，或许能更快发现问题，该反思反思。\r\n\r\n1. 谁调用了EVP_Q_mac？\r\n    1. Ipmi并没有直接调用该函数，那就是间接调用，如果库没有带符号表，那问题复杂度更高了。\r\n        \r\n        **（1）没有符号表**\r\n        \r\n        1. **如果是直接调用，我们直接打印参数内容**\r\n        2. **间接调用，需要找到EVP_Q_mac的各种引用函数，再一个个追踪引用函数**\r\n        \r\n        **（2）有符号表：通过设置断点，在栈被破坏前，把函数停住，把栈先打出来，这样就清楚异常的具体位置了。**\r\n        \r\n        1. 在异常的位置设置一个断点\r\n        2. run\r\n        3. 在运行到断点的时候自动停止，执行bt，通过这个方式就能看到异常的点在read password了\r\n        ![](https://kelephant.github.io/gridea/post-images/1712674496787.png)\r\n\r\n    2. 栈为什么被破坏？被破坏的栈有没有办法恢复，或者调试手段防止栈被破坏？\r\n        1. Gdb在执行时是否能加参数，保护栈不被破坏？似乎没有找到解决办法\r\n        2. Gcc编译参数，参考下面的文章：https://outflux.net/blog/archives/2014/01/27/fstack-protector-strong/\r\n\r\n# 64位系统地址翻译\r\n\r\n1. 找到异常地址对应的段（/proc/{pid}/maps）\r\n2. 将地址与段的起始地址，作差，即可得到异常的位置\r\n3. 如果是.so文件，通过objdump -d libcrypto.so.3 | grep 1b02a0(这个是作差后的值)\r\n4. 如果是可执行文件，通过addr2line即可\r\n\r\n# 其他\r\n\r\n## 动态库加载情况\r\n\r\ninfo sharedlibrary\r\n\r\n## 所有线程的bt\r\n\r\nthread apply all bt\r\n\r\n使用该办法可以定位死锁问题",
      "data": {
        "title": "openbmc 异常栈分析及复盘",
        "date": "2024-04-09 22:53:33",
        "tags": [
          "openbmc",
          "coredump",
          "debug"
        ],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "Openbmc ipmi在运行之后，出现段错误\r",
      "fileName": "openbmc-yi-chang-zhan-fen-xi-ji-fu-pan"
    },
    {
      "content": "# Kernel关机死锁问\r\n\r\n# 背景\r\n\r\n## 内核版本\r\n\r\nLinux 4.4.194 ohci_hcd\r\n\r\n## 问题描述\r\n\r\n**执行shutdown -h now**\r\n```\r\n[  OK  ] Stopped Load Kernel Modules.\r\n\r\n[  OK  ] Unmounted /share.\r\n\r\n[  OK  ] Stopped target Local File Systems (Pre).\r\n\r\n[  OK  ] Reached target Unmount All Filesystems.\r\n\r\n[  OK  ] Stopped Create Static Device Nodes in /dev.\r\n\r\n[  OK  ] Stopped Create System Users.\r\n\r\n[  OK  ] Stopped Remount Root and Kernel File Systems.\r\n\r\n[  OK  ] Reached target Shutdown.\r\n\r\n[  OK  ] Reached target Final Step.\r\n\r\n[  OK  ] Finished Power-Off.\r\n\r\n[  OK  ] Reached target Power-Off.\r\n\r\n[   69.279680]\r\n\r\n[   69.281172] ======================================================\r\n\r\n[   69.287345] [ INFO: possible circular locking dependency detected ]\r\n\r\n[   69.293605] 4.4.194 #1 Not tainted\r\n\r\n[   69.297001] -------------------------------------------------------\r\n\r\n[   69.303265] systemd-shutdow/1 is trying to acquire lock:\r\n\r\n[   69.303286]  (&policy->rwsem){+++++.}, at: [<ffffff800884335c>] cpufreq_update_policy+0x40/0x158\r\n\r\n[   69.303287]\r\n\r\n[   69.303287] but task is already holding lock:\r\n\r\n[   69.303300]  (mdev_list_sem){++++..}, at: [<ffffff80085577d0>] rockchip_system_status_notifier+0x34/0x118\r\n\r\n[   69.303302]\r\n\r\n[   69.303302] which lock already depends on the new lock.\r\n\r\n[   69.303302]\r\n\r\n[   69.303303]\r\n\r\n[   69.303303] the existing dependency chain (in reverse order) is:\r\n\r\n[   69.303307]\r\n\r\n[   69.303307] -> #2 (mdev_list_sem){++++..}:\r\n\r\n[   69.303313]        [<ffffff800811f264>] __lock_acquire+0x1348/0x191c\r\n\r\n[   69.303317]        [<ffffff800811febc>] lock_acquire+0x1e0/0x23c\r\n\r\n[   69.303323]        [<ffffff8008c4ea64>] down_read+0x5c/0xdc\r\n\r\n[   69.303327DDR Version 1.24 20191016\r\n\r\nIn\r\n\r\n---\r\n\r\n执行reboot，内核deadlock，会自动重启\r\n\r\nStopping WPA supplicant...\r\n\r\n[  OK  ] Stopped WPA supplicant.\r\n\r\nStopping D-Bus System Message Bus...\r\n\r\n[  OK  ] Stopped D-Bus System Message Bus.\r\n\r\n[  OK  ] Stopped target Basic System.\r\n\r\n[  OK  ] Stopped target Paths.\r\n\r\n[  OK  ] Stopped target Slices.\r\n\r\n[  OK  ] Removed slice User and Session Slice.\r\n\r\n[  OK  ] Stopped target Sockets.\r\n\r\n[  OK  ] Closed D-Bus System Message Bus Socket.\r\n\r\n[  OK  ] Closed Docker Socket for the API.\r\n\r\n[  OK  ] Stopped target System Initialization.\r\n\r\n[  OK  ] Stopped target Local Encrypted Volumes.\r\n\r\n[  OK  ] Stopped Dispatch Password …ts to Console Directory Watch.\r\n\r\n[  OK  ] Stopped Forward Password R…uests to Wall Directory Watch.\r\n\r\n[  OK  ] Stopped target Swap.\r\n\r\n[  OK  ] Closed Syslog Socket.\r\n\r\nStopping Network Time Synchronization...\r\n\r\nStopping Update UTMP about System Boot/Shutdown...\r\n\r\n[  OK  ] Stopped Network Name Resolution.\r\n\r\n[  OK  ] Stopped Update UTMP about System Boot/Shutdown.\r\n\r\n[  OK  ] Stopped ifup for eth0.\r\n\r\n[  OK  ] Stopped Network Time Synchronization.\r\n\r\n[  OK  ] Stopped Create Volatile Files and Directories.\r\n\r\n[  OK  ] Stopped ifup for eth1.13.\r\n\r\n[  OK  ] Stopped ifup for eth1.\r\n\r\n[  OK  ] Stopped Raise network interfaces.\r\n\r\n[  OK  ] Stopped target Local File Systems.\r\n\r\nUnmounting /share...\r\n\r\n[  OK  ] Stopped Apply Kernel Variables.\r\n\r\n[  OK  ] Stopped Load Kernel Modules.\r\n\r\n[  OK  ] Unmounted /share.\r\n\r\n[  OK  ] Stopped target Local File Systems (Pre).\r\n\r\n[  OK  ] Reached target Unmount All Filesystems.\r\n\r\n[  OK  ] Stopped Create Static Device Nodes in /dev.\r\n\r\n[  OK  ] Stopped Create System Users.\r\n\r\n[  OK  ] Stopped Remount Root and Kernel File Systems.\r\n\r\n[  OK  ] Reached target Shutdown.\r\n\r\n[  OK  ] Reached target Final Step.\r\n\r\n[  OK  ] Finished Reboot.\r\n\r\n[  OK  ] Reached target Reboot.\r\n\r\n[   21.169263] dw_wdt: unexpected close, system will reboot soon\r\n\r\n[   21.550470]\r\n\r\n[   21.551963] ======================================================\r\n\r\n[   21.558139] [ INFO: possible circular locking dependency detected ]\r\n\r\n[   21.564401] 4.4.194 #1 Not tainted\r\n\r\n[   21.567799] -------------------------------------------------------\r\n\r\n[   21.574059] systemd-shutdow/1 is trying to acquire lock:\r\n\r\n[   21.579364]  (&policy->rwsem){+++++.}, at: [<ffffff800884335c>] cpufreq_update_policy+0x40/0x158\r\n\r\n[   21.588223]\r\n\r\n[   21.588223] but task is already holding lock:\r\n\r\n[   21.594049]  (mdev_list_sem){++++..}, at: [<ffffff80085577d0>] rockchip_system_status_notifier+0x34/0x118\r\n\r\n[   21.603681]\r\n\r\n[   21.603681] which lock already depends on the new lock.\r\n\r\n[   21.603681]\r\n\r\n[   21.611852]\r\n\r\n[   21.611852] the existing dependency chain (in reverse order) is:\r\n\r\n[   21.619321]\r\n\r\n- > #2 (mdev_list_sem){++++..}:\r\n\r\n[   21.623668]        [<ffffff800811f264>] __lock_acquire+0x1348/0x191c\r\n\r\n[   21.630031]        [<ffffff800811febc>] lock_acquire+0x1e0/0x23c\r\n\r\n[   21.636052]        [<ffffff8008c4ea64>] down_read+0x5c/0xdc\r\n\r\n[   21.641641]        [<ffffff8008557310>] rockchip_monitor_cpufreq_policy_notifier+0x48/0x18c\r\n\r\n[   21.649995]        [<ffffff80080e0c94>] notifier_call_chain+0x78/0x98\r\n\r\n[   21.656451]        [<ffffff80080e10b0>] __blocking_notifier_call_chain+0x58/0x84\r\n\r\n[   21.663850]        [<ffffff80080e1118>] blocking_notifier_call_chain+0x3c/0x4c\r\n\r\n[   21.671079]        [<ffffff8008842f48>] cpufreq_set_policy+0xac/0x480\r\n\r\n[   21.677535]        [<ffffff8008843adc>] cpufreq_init_policy+0x90/0xc0\r\n\r\n[   21.683990]        [<ffffff80088443a4>] cpufreq_online+0x694/0x70c\r\n\r\n[   21.690181]        [<ffffff8008844514>] cpufreq_add_dev+0x7c/0xd0\r\n\r\n[   21.696286]        [<ffffff800865d148>] subsys_interface_register+0xb8/0xcc\r\n\r\n[   21.703264]        [<ffffff80088437b8>] cpufreq_register_driver+0x134/0x204\r\n\r\n[   21.710239]        [<ffffff800884dff4>] dt_cpufreq_probe+0x158/0x174\r\n\r\n[   21.716600]        [<ffffff80086611fc>] platform_drv_probe+0x5c/0xb0\r\n\r\n[   21.722960]        [<ffffff800865ed5c>] driver_probe_device+0x264/0x3d4\r\n\r\n[   21.729585]        [<ffffff800865f034>] __device_attach_driver+0x68/0xa4\r\n\r\n[   21.736295]        [<ffffff800865ce08>] bus_for_each_drv+0x90/0xa0\r\n\r\n[   21.742486]        [<ffffff800865e9e8>] __device_attach+0xb4/0x130\r\n\r\n[   21.748676]        [<ffffff800865f1d0>] device_initial_probe+0x24/0x30\r\n\r\n[   21.755217]        [<ffffff800865de5c>] bus_probe_device+0x38/0x9c\r\n\r\n[   21.761407]        [<ffffff800865bb84>] device_add+0x480/0x528\r\n\r\n[   21.767247]        [<ffffff8008660ee4>] platform_device_add+0xe8/0x22c\r\n\r\n[   21.773786]        [<ffffff8008661ae8>] platform_device_register_full+0xac/0xec\r\n\r\n[   21.781100]        [<ffffff80091fd464>] rockchip_cpufreq_driver_init+0xb8/0x2f8\r\n\r\n[   21.788417]        [<ffffff80080830f8>] do_one_initcall+0x78/0x198\r\n\r\n[   21.794608]        [<ffffff80091c0e94>] kernel_init_freeable+0x27c/0x280\r\n\r\n[   21.801319]        [<ffffff8008c4a0e8>] kernel_init+0x18/0x100\r\n\r\n[   21.807159]        [<ffffff8008082f10>] ret_from_fork+0x10/0x40\r\n\r\n[   21.813084]\r\n\r\n- > #1 ((cpufreq_policy_notifier_list).rwsem){.+.+.+}:\r\n\r\n[   21.819422]        [<ffffff800811f264>] __lock_acquire+0x1348/0x191c\r\n\r\n[   21.825782]        [<ffffff800811febc>] lock_acquire+0x1e0/0x23c\r\n\r\n[   21.831803]        [<ffffff8008c4ea64>] down_read+0x5c/0xdc\r\n\r\n[   21.837389]        [<ffffff80080e1098>] __blocking_notifier_call_chain+0x40/0x84\r\n\r\n[   21.844787]        [<ffffff80080e1118>] blocking_notifier_call_chain+0x3c/0x4c\r\n\r\n[   21.852015]        [<ffffff8008844350>] cpufreq_online+0x640/0x70c\r\n\r\n[   21.858206]        [<ffffff8008844514>] cpufreq_add_dev+0x7c/0xd0\r\n\r\n[   21.864312]        [<ffffff800865d148>] subsys_interface_register+0xb8/0xcc\r\n\r\n[   21.871287]        [<ffffff80088437b8>] cpufreq_register_driver+0x134/0x204\r\n\r\n[   21.878262]        [<ffffff800884dff4>] dt_cpufreq_probe+0x158/0x174\r\n\r\n[   21.884623]        [<ffffff80086611fc>] platform_drv_probe+0x5c/0xb0\r\n\r\n[   21.890982]        [<ffffff800865ed5c>] driver_probe_device+0x264/0x3d4\r\n\r\n[   21.897607]        [<ffffff800865f034>] __device_attach_driver+0x68/0xa4\r\n\r\n[   21.904317]        [<ffffff800865ce08>] bus_for_each_drv+0x90/0xa0\r\n\r\n[   21.910507]        [<ffffff800865e9e8>] __device_attach+0xb4/0x130\r\n\r\n[   21.916698]        [<ffffff800865f1d0>] device_initial_probe+0x24/0x30\r\n\r\n[   21.923238]        [<ffffff800865de5c>] bus_probe_device+0x38/0x9c\r\n\r\n[   21.929429]        [<ffffff800865bb84>] device_add+0x480/0x528\r\n\r\n[   21.935269]        [<ffffff8008660ee4>] platform_device_add+0xe8/0x22c\r\n\r\n[   21.941809]        [<ffffff8008661ae8>] platform_device_register_full+0xac/0xec\r\n\r\n[   21.949122]        [<ffffff80091fd464>] rockchip_cpufreq_driver_init+0xb8/0x2f8\r\n\r\n[   21.956436]        [<ffffff80080830f8>] do_one_initcall+0x78/0x198\r\n\r\n[   21.962626]        [<ffffff80091c0e94>] kernel_init_freeable+0x27c/0x280\r\n\r\n[   21.969335]        [<ffffff8008c4a0e8>] kernel_init+0x18/0x100\r\n\r\n[   21.975176]        [<ffffff8008082f10>] ret_from_fork+0x10/0x40\r\n\r\n[   21.981101]\r\n\r\n- > #0 (&policy->rwsem){+++++.}:\r\n\r\n[   21.985531]        [<ffffff800811ae44>] print_circular_bug+0x60/0x2bc\r\n\r\n[   21.991986]        [<ffffff800811ee1c>] __lock_acquire+0xf00/0x191c\r\n\r\n[   21.998261]        [<ffffff800811febc>] lock_acquire+0x1e0/0x23c\r\n\r\n[   22.004281]        [<ffffff8008c4eb44>] down_write+0x60/0xd8\r\n\r\n[   22.009953]        [<ffffff800884335c>] cpufreq_update_policy+0x40/0x158\r\n\r\n[   22.016663]        [<ffffff8008557878>] rockchip_system_status_notifier+0xdc/0x118\r\n\r\n[   22.024243]        [<ffffff80080e0c94>] notifier_call_chain+0x78/0x98\r\n\r\n[   22.030697]        [<ffffff80080e10b0>] __blocking_notifier_call_chain+0x58/0x84\r\n\r\n[   22.038096]        [<ffffff80080e1118>] blocking_notifier_call_chain+0x3c/0x4c\r\n\r\n[   22.045324]        [<ffffff8008556b58>] rockchip_system_status_notifier_call_chain+0x2c/0x54\r\n\r\n[   22.053773]        [<ffffff8008556be8>] rockchip_set_system_status+0x68/0xc8\r\n\r\n[   22.060833]        [<ffffff8008557628>] rockchip_monitor_reboot_notifier+0x18/0x3c\r\n\r\n[   22.068412]        [<ffffff80080e0c94>] notifier_call_chain+0x78/0x98\r\n\r\n[   22.074867]        [<ffffff80080e10b0>] __blocking_notifier_call_chain+0x58/0x84\r\n\r\n[   22.082265]        [<ffffff80080e1118>] blocking_notifier_call_chain+0x3c/0x4c\r\n\r\n[   22.089493]        [<ffffff80080e2f54>] kernel_restart_prepare+0x2c/0x50\r\n\r\n[   22.096203]        [<ffffff80080e30a0>] kernel_restart+0x20/0x68\r\n\r\n[   22.102223]        [<ffffff80080e33f8>] SyS_reboot+0x180/0x1dc\r\n\r\n[   22.108064]        [<ffffff8008082f70>] el0_svc_naked+0x24/0x28\r\n\r\n[   22.113989]\r\n\r\n[   22.113989] other info that might help us debug this:\r\n\r\n[   22.113989]\r\n\r\n[   22.121980] Chain exists of:\r\n\r\n&policy->rwsem --> (cpufreq_policy_notifier_list).rwsem --> mdev_list_sem\r\n\r\n[   22.131813]  Possible unsafe locking scenario:\r\n\r\n[   22.131813]\r\n\r\n[   22.137724]        CPU0                    CPU1\r\n\r\n[   22.142255]        ----                    ----\r\n\r\n[   22.146787]   lock(mdev_list_sem);\r\n\r\n[   22.150223]                                lock((cpufreq_policy_notifier_list).rwsem);\r\n\r\n[   22.158164]                                lock(mdev_list_sem);\r\n\r\n[   22.164111]   lock(&policy->rwsem);\r\n\r\n[   22.167632]\r\n\r\n[   22.167632]  *** DEADLOCK ***\r\n\r\n[   22.167632]\r\n\r\n[   22.173545] 5 locks held by systemd-shutdow/1:\r\n\r\n[   22.177980]  #0:  (reboot_mutex){+.+...}, at: [<ffffff80080e3378>] SyS_reboot+0x100/0x1dc\r\n\r\n[   22.186233]  #1:  ((reboot_notifier_list).rwsem){.+.+..}, at: [<ffffff80080e1098>] __blocking_notifier_call_chain+0x40/0x84\r\n\r\n[   22.197441]  #2:  (system_status_mutex){+.+...}, at: [<ffffff8008556bac>] rockchip_set_system_status+0x2c/0xc8\r\n\r\n[   22.207527]  #3:  ((system_status_notifier_list).rwsem){.+.+..}, at: [<ffffff80080e1098>] __blocking_notifier_call_chain+0x40/0x84\r\n\r\n[   22.219339]  #4:  (mdev_list_sem){++++..}, at: [<ffffff80085577d0>] rockchip_system_status_notifier+0x34/0x118\r\n\r\n[   22.229425]\r\n\r\n[   22.229425] stack backtrace:\r\n\r\n[   22.233781] CPU: 4 PID: 1 Comm: systemd-shutdow Not tainted 4.4.194 #1\r\n\r\n[   22.240306] Hardware name: Rockchip RK3399 Board Vclusters (DT)\r\n\r\n[   22.246218] Call trace:\r\n\r\n[   22.248664] [<ffffff8008088a40>] dump_backtrace+0x0/0x234\r\n\r\n[   22.254057] [<ffffff8008088c98>] show_stack+0x24/0x30\r\n\r\n[   22.259111] [<ffffff80084b0ba4>] dump_stack+0xb4/0xf4\r\n\r\n[   22.264163] [<ffffff800811afcc>] print_circular_bug+0x1e8/0x2bc\r\n\r\n[   22.270075] [<ffffff800811ee1c>] __lock_acquire+0xf00/0x191c\r\n\r\n[   22.275731] [<ffffff800811febc>] lock_acquire+0x1e0/0x23c\r\n\r\n[   22.281124] [<ffffff8008c4eb44>] down_write+0x60/0xd8\r\n\r\n[   22.286177] [<ffffff800884335c>] cpufreq_update_policy+0x40/0x158\r\n\r\n[   22.292270] [<ffffff8008557878>] rockchip_system_status_notifier+0xdc/0x118\r\n\r\n[   22.299221] [<ffffff80080e0c94>] notifier_call_chain+0x78/0x98\r\n\r\n[   22.305047] [<ffffff80080e10b0>] __blocking_notifier_call_chain+0x58/0x84\r\n\r\n[   22.311828] [<ffffff80080e1118>] blocking_notifier_call_chain+0x3c/0x4c\r\n\r\n[   22.318440] [<ffffff8008556b58>] rockchip_system_status_notifier_call_chain+0x2c/0x54\r\n\r\n[   22.326262] [<ffffff8008556be8>] rockchip_set_system_status+0x68/0xc8\r\n\r\n[   22.332693] [<ffffff8008557628>] rockchip_monitor_reboot_notifier+0x18/0x3c\r\n\r\n[   22.339644] [<ffffff80080e0c94>] notifier_call_chain+0x78/0x98\r\n\r\n[   22.345470] [<ffffff80080e10b0>] __blocking_notifier_call_chain+0x58/0x84\r\n\r\n[   22.352251] [<ffffff80080e1118>] blocking_notifier_call_chain+0x3c/0x4c\r\n\r\n[   22.358863] [<ffffff80080e2f54>] kernel_restart_prepare+0x2c/0x50\r\n\r\n[   22.364954] [<ffffff80080e30a0>] kernel_restart+0x20/0x68\r\n\r\n[   22.370346] [<ffffff80080e33f8>] SyS_reboot+0x180/0x1dc\r\n\r\n[   22.375568] [<ffffff8008082f70>] el0_svc_naked+0x24/0x28\r\n\r\n[   22.381157] cpu cpu4: min=816000, max=816000\r\n\r\n[   22.386760] cpu cpu0: min=816000, max=816000\r\n\r\n[   22.401700] rk-vcodec ff660000.rkvdec: shutdown\r\n\r\n[   22.406278] rk-vcodec ff650000.vpu_service: shutdown\r\n\r\n[   22.415938] reboot: Restarting system\r\n\r\n```\r\n\r\n## 原因\r\n\r\nRockchip在初始化时，会注册一个cpu状态更新和cpu策略更新的通知回调。两个回调都会对mdev_list_sem上锁\r\n\r\n关机时会更新cpu状态（怀疑关机就是将CPU频率设置为0，这样CPU就不工作了）\r\n\r\n更新cpu频率时cpufreq驱动会通知rockchip_system_status_notifier更新cpu状态\r\n\r\nRockchip在更新cpu状态时，反过来再去设置cpu频率并更新CPU策略\r\n\r\n而上一次更新CPU状态时，已经对mdev_list_sem上锁并未释放，现在更新CPU策略又要再次对它上锁，因而死锁\r\n\r\n## 解决办法\r\n\r\n在更新CPU设备状态时，先不着急更新CPU策略。\r\n\r\n先把所有CPU 设备状态更新了，并记录哪些CPU设备状态已经更新，然后释放锁。\r\n\r\n再更新记录的CPU设备策略。死锁解决\r\n\r\n# 结束",
      "data": {
        "title": "记一次内核死锁的调试过程",
        "date": "2024-04-09 22:39:02",
        "tags": [],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "ji-yi-ci-nei-he-si-suo-de-diao-shi-guo-cheng"
    },
    {
      "content": "在实际的线上环境中，如果遇到了问题，程序没有退出，并且我们并不希望停止运行的程序时，就要求在在运行时调试程序\r\n\r\n但是通过gdb attach调试，可能在操作过程中，会不小心破坏运行时程序，影响服务\r\n\r\n这个时候可以将运行中的进程内存，dump下来，完了使用gdb调试dump下来的信息\r\n\r\n<!-- more -->\r\n\r\n# 具体操作\r\n\r\n```\r\n1. gcore 获取core dump\r\nroot@localhost:/share/wenqikai# gcore 177389\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n0x00007fad882d607b in pselect () from /lib/x86_64-linux-gnu/libc.so.6\r\nwarning: Memory read failed for corefile section, 4096 bytes at 0xffffffffff600000.\r\nSaved corefile core.177389\r\n[Inferior 1 (process 177389) detached]\r\n\r\n2. 调试\r\nroot@localhost:/share/wenqikai# gdb /usr/bin/top ./core.177389 \r\nGNU gdb (Ubuntu 9.2-0ubuntu1~20.04.1) 9.2\r\nCopyright (C) 2020 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-linux-gnu\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\"...\r\nReading symbols from /usr/bin/top...\r\n(No debugging symbols found in /usr/bin/top)\r\n[New LWP 177389]\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\nCore was generated by `top'.\r\n#0  0x00007fad882d607b in __pselect (nfds=1, readfds=0x7ffd719b9a60, writefds=0x0, exceptfds=0x0, timeout=<optimized out>, sigmask=0x55a455914380)\r\n    at ../sysdeps/unix/sysv/linux/pselect.c:48\r\n48      ../sysdeps/unix/sysv/linux/pselect.c: No such file or directory.\r\n(gdb) bt\r\n#0  0x00007fad882d607b in __pselect (nfds=1, readfds=0x7ffd719b9a60, writefds=0x0, exceptfds=0x0, timeout=<optimized out>, sigmask=0x55a455914380)\r\n    at ../sysdeps/unix/sysv/linux/pselect.c:48\r\n#1  0x000055a4558d2bba in ?? ()\r\n#2  0x00007fad881e5083 in __libc_start_main (main=0x55a4558d1e00, argc=1, argv=0x7ffd719b9c98, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, \r\n    stack_end=0x7ffd719b9c88) at ../csu/libc-start.c:308\r\n#3  0x000055a4558d334e in ?? ()\r\n(gdb) info threads \r\n  Id   Target Id                          Frame \r\n* 1    Thread 0x7fad87f4d7c0 (LWP 177389) 0x00007fad882d607b in __pselect (nfds=1, readfds=0x7ffd719b9a60, writefds=0x0, exceptfds=0x0, timeout=<optimized out>, \r\n    sigmask=0x55a455914380) at ../sysdeps/unix/sysv/linux/pselect.c:48\r\n(gdb) qQuit\r\n(gdb) qQuit\r\n```",
      "data": {
        "title": "运行时程序内存dump",
        "date": "2024-04-09 15:58:08",
        "tags": [
          "debug",
          "gdb",
          "coredump"
        ],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "在实际的线上环境中，如果遇到了问题，程序没有退出，并且我们并不希望停止运行的程序时，就要求在在运行时调试程序\r\n\r\n但是通过gdb attach调试，可能在操作过程中，会不小心破坏运行时程序，影响服务\r\n\r\n这个时候可以将运行中的进程内存，dump下来，完了使用gdb调试dump下来的信息\r",
      "fileName": "yun-xing-shi-cheng-xu-nei-cun-dump"
    },
    {
      "content": "# 参考文章\r\n\r\n1. 该链接讲述了Call Trace 的调试方法\r\n[decode-kernel-call-trace.md](https://gist.github.com/doughgle/735229c34c52f9006ca92a2cf24da990)\r\n\r\n2. 带symbol的内核镜像安装，正常情况下/usr/lib/debug/boot/会保存带symbol的内核镜像，如果找不到，可以按照以下方式自行\r\n[https://wiki.ubuntu.com/Debug Symbol Packages](https://wiki.ubuntu.com/Debug%20Symbol%20Packages)\r\n\r\n# 调试步骤\r\n\r\n## 创建调试目录\r\n\r\n```jsx\r\nmkdir -p ~/workspace/call_trace\r\n```\r\n\r\n## 设计异常模块\r\n\r\n1. 创建kernel_call_trace.c文件\r\n\r\n```jsx\r\n#include <linux/kernel.h>\r\n#include <linux/module.h>\r\n#include <linux/mm.h>\r\n\r\nchar *ptr = NULL;\r\n\r\nint __init init_module(void) {\r\n  //ptr = kmalloc(sizeof(int), GFP_KERNEL);\r\n\r\n  *ptr = 0;\r\n\r\n  printk(KERN_ALERT \"Call trace:\\n\");\r\n  //backtrace();\r\n\r\n  // BUG();\r\n\r\n  return 0;\r\n}\r\n\r\nvoid __exit cleanup_module(void) {\r\n  //kfree(ptr);\r\n}\r\n```\r\n\r\n2. 创建Makefile文件\r\n```jsx\r\nobj-m := kernel_call_trace.o\r\n\r\nall:\r\n        make -C /usr/src/linux-headers-$(shell uname -r) M=$(PWD) modules\r\n\r\nclean:\r\n        make -C /usr/src/linux-headers-$(shell uname -r) M=$(PWD) clean\r\n```\r\n\r\n3. make，生成 kernel_call_trace.ko 模块\r\n```jsx\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ make \r\nmake -C /usr/src/linux-headers-6.2.0-37-generic M=/home/wenqikai/workspace/call_trace modules\r\nmake[1]: Entering directory '/usr/src/linux-headers-6.2.0-37-generic'\r\nwarning: the compiler differs from the one used to build the kernel\r\n  The kernel was built by: x86_64-linux-gnu-gcc-11 (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n  You are using:           gcc-11 (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\r\n  CC [M]  /home/wenqikai/workspace/call_trace/kernel_call_trace.o\r\n  MODPOST /home/wenqikai/workspace/call_trace/Module.symvers\r\n  CC [M]  /home/wenqikai/workspace/call_trace/kernel_call_trace.mod.o\r\n  LD [M]  /home/wenqikai/workspace/call_trace/kernel_call_trace.ko\r\n  BTF [M] /home/wenqikai/workspace/call_trace/kernel_call_trace.ko\r\nSkipping BTF generation for /home/wenqikai/workspace/call_trace/kernel_call_trace.ko due to unavailability of vmlinux\r\nmake[1]: Leaving directory '/usr/src/linux-headers-6.2.0-37-generic'\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ ls -l\r\ntotal 264\r\n-rw-rw-r-- 1 wenqikai wenqikai   3611 12月 19 13:37 call_trace.log\r\n-rwxr-xr-x 1 wenqikai wenqikai   7383 12月 19 11:26 decode_stacktrace.sh\r\n-rw-rw-r-- 1 wenqikai wenqikai    343 12月 19 11:33 kernel_call_trace.c\r\n-rw-rw-r-- 1 wenqikai wenqikai 115376 12月 19 14:13 kernel_call_trace.ko\r\n-rw-rw-r-- 1 wenqikai wenqikai     56 12月 19 14:13 kernel_call_trace.mod\r\n-rw-rw-r-- 1 wenqikai wenqikai    891 12月 19 14:13 kernel_call_trace.mod.c\r\n-rw-rw-r-- 1 wenqikai wenqikai  93400 12月 19 14:13 kernel_call_trace.mod.o\r\n-rw-rw-r-- 1 wenqikai wenqikai  23344 12月 19 14:13 kernel_call_trace.o\r\n-rw-rw-r-- 1 wenqikai wenqikai    176 12月 19 14:12 Makefile\r\n-rw-rw-r-- 1 wenqikai wenqikai     56 12月 19 14:13 modules.order\r\n-rw-rw-r-- 1 wenqikai wenqikai      0 12月 19 14:13 Module.symvers\r\n```\r\n\r\n4. 加载kernel_call_trace.ko 模块，由于该内核模块是我们故意制造异常的，所以在一加载时便会报错，通过dmesg可以查到call trace信息。下面标红部分是call trace的完整信息，其中其中标蓝部分表示异常的模块名\r\n```jsx\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ sudo insmod  kernel_call_trace.ko \r\n[sudo] password for wenqikai: \r\nKilled\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ sudo dmesg | tail -100\r\n...\r\n[ 2023-12-19 11:34:15 ] [70466.575935] Call Trace:\r\n[ 2023-12-19 11:34:15 ] [70466.578246]  <TASK>\r\n[ 2023-12-19 11:34:15 ] [70466.585635]  ? show_regs+0x72/0x90\r\n[ 2023-12-19 11:34:15 ] [70466.614356]  ? __die+0x25/0x80\r\n[ 2023-12-19 11:34:15 ] [70466.614381]  ? page_fault_oops+0x79/0x190\r\n[ 2023-12-19 11:34:15 ] [70466.615773]  ? do_user_addr_fault+0x30c/0x640\r\n[ 2023-12-19 11:34:15 ] [70466.615775]  ? down_write+0x13/0x90\r\n[ 2023-12-19 11:34:15 ] [70466.634448]  ? exc_page_fault+0x81/0x1b0\r\n[ 2023-12-19 11:34:15 ] [70466.635485]  ? asm_exc_page_fault+0x27/0x30\r\n[ 2023-12-19 11:34:15 ] [70466.635793]  ? __pfx_init_module+0x10/0x10 [kernel_call_trace]\r\n[ 2023-12-19 11:34:15 ] [70466.635802]  ? init_module+0x14/0xff0 [kernel_call_trace]\r\n[ 2023-12-19 11:34:15 ] [70466.635806]  ? do_one_initcall+0x46/0x240\r\n[ 2023-12-19 11:34:15 ] [70466.635870]  ? kmalloc_trace+0x2a/0xb0\r\n[ 2023-12-19 11:34:15 ] [70466.636483]  do_init_module+0x52/0x240\r\n[ 2023-12-19 11:34:15 ] [70466.636737]  load_module+0xb96/0xd60\r\n[ 2023-12-19 11:34:15 ] [70466.636740]  ? kernel_read_file+0x25c/0x2b0\r\n[ 2023-12-19 11:34:15 ] [70466.636965]  __do_sys_finit_module+0xcc/0x150\r\n[ 2023-12-19 11:34:15 ] [70466.636967]  ? __do_sys_finit_module+0xcc/0x150\r\n[ 2023-12-19 11:34:15 ] [70466.636972]  __x64_sys_finit_module+0x18/0x30\r\n[ 2023-12-19 11:34:15 ] [70466.636974]  do_syscall_64+0x59/0x90\r\n[ 2023-12-19 11:34:15 ] [70466.636994]  ? irqentry_exit+0x43/0x50\r\n[ 2023-12-19 11:34:15 ] [70466.636997]  ? exc_page_fault+0x92/0x1b0\r\n[ 2023-12-19 11:34:15 ] [70466.637000]  entry_SYSCALL_64_after_hwframe+0x73/0xdd\r\n[ 2023-12-19 11:34:15 ] [70466.637003] RIP: 0033:0x7ff0b911e69d\r\n[ 2023-12-19 11:34:15 ] [70466.637007] Code: 5b 41 5c c3 66 0f 1f 84 00 00 00 00 00 f3 0f 1e fa 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 63 a7 0f 00 f7 d8 64 89 01 48\r\n[ 2023-12-19 11:34:15 ] [70466.637009] RSP: 002b:00007fff662d0fc8 EFLAGS: 00000246 ORIG_RAX: 0000000000000139\r\n[ 2023-12-19 11:34:15 ] [70466.637012] RAX: ffffffffffffffda RBX: 0000562af52237b0 RCX: 00007ff0b911e69d\r\n[ 2023-12-19 11:34:15 ] [70466.637013] RDX: 0000000000000000 RSI: 0000562af4eb5cd2 RDI: 0000000000000003\r\n[ 2023-12-19 11:34:15 ] [70466.637015] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000\r\n[ 2023-12-19 11:34:15 ] [70466.637016] R10: 0000000000000003 R11: 0000000000000246 R12: 0000562af4eb5cd2\r\n[ 2023-12-19 11:34:15 ] [70466.637018] R13: 0000562af5223760 R14: 0000562af4eb4888 R15: 0000562af52238d0\r\n```\r\n\r\n5. 将Call Trace信息存储到call_trace.log文件中\r\n6. 拷贝内核符号表解析工具到当前目录下\r\n```jsx\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ cp /usr/src/linux-headers-$(uname -r)/scripts/decode_stacktrace.sh .\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ ls -l\r\ntotal 264\r\n-rw-rw-r-- 1 wenqikai wenqikai   3611 12月 19 13:37 call_trace.log\r\n-rwxr-xr-x 1 wenqikai wenqikai   7383 12月 19 14:22 decode_stacktrace.sh\r\n-rw-rw-r-- 1 wenqikai wenqikai    343 12月 19 11:33 kernel_call_trace.c\r\n-rw-rw-r-- 1 wenqikai wenqikai 115376 12月 19 14:13 kernel_call_trace.ko\r\n-rw-rw-r-- 1 wenqikai wenqikai     56 12月 19 14:13 kernel_call_trace.mod\r\n-rw-rw-r-- 1 wenqikai wenqikai    891 12月 19 14:13 kernel_call_trace.mod.c\r\n-rw-rw-r-- 1 wenqikai wenqikai  93400 12月 19 14:13 kernel_call_trace.mod.o\r\n-rw-rw-r-- 1 wenqikai wenqikai  23344 12月 19 14:13 kernel_call_trace.o\r\n-rw-rw-r-- 1 wenqikai wenqikai    176 12月 19 14:12 Makefile\r\n-rw-rw-r-- 1 wenqikai wenqikai     56 12月 19 14:13 modules.order\r\n-rw-rw-r-- 1 wenqikai wenqikai      0 12月 19 14:13 Module.symvers\r\n```\r\n\r\n7. 使用以下目录解析\r\n./decode_stacktrace.sh /usr/lib/debug/boot/vmlinux-$(uname -r)  auto /home/wenqikai/workspace/call_trace/ < call_trace.log \r\n\r\n参数解析：\r\n- ./decode_stacktrace.sh：解析程序\r\n- /usr/lib/debug/boot/vmlinux-$(uname -r)：带符号表的内核文件，如果找不到该文件，则参考该链接操作安装[https://wiki.ubuntu.com/Debug Symbol Packages](https://wiki.ubuntu.com/Debug%20Symbol%20Packages)\r\n- auto： 这里应该是自动找到系统模块目录\r\n- /home/wenqikai/workspace/call_trace/：这里是我们自己的模块存放目录\r\n- call_trace.log：call trace文件\r\n```jsx\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ ./decode_stacktrace.sh \r\nERROR! vmlinux image must be specified\r\nUsage:\r\n        ./decode_stacktrace.sh -r <release> | <vmlinux> [<base path>|auto] [<modules path>]\r\nwenqikai@wenqikai-virtual-machine:~/workspace/call_trace$ ./decode_stacktrace.sh /usr/lib/debug/boot/vmlinux-$(uname -r)  auto /home/wenqikai/workspace/call_trace/ < call_trace.log \r\n[70466.575935] Call Trace:\r\n[70466.578246]  <TASK>\r\n[70466.585635] ? show_regs (arch/x86/kernel/dumpstack.c:479) \r\n[70466.614356] ? __die (arch/x86/kernel/dumpstack.c:421 arch/x86/kernel/dumpstack.c:434) \r\n[70466.614381] ? page_fault_oops (arch/x86/mm/fault.c:727) \r\n[70466.615773] ? do_user_addr_fault (arch/x86/mm/fault.c:1270) \r\n[70466.615775] ? down_write (arch/x86/include/asm/preempt.h:80 kernel/locking/rwsem.c:261 kernel/locking/rwsem.c:1313 kernel/locking/rwsem.c:1323 kernel/locking/rwsem.c:1574) \r\n[70466.634448] ? exc_page_fault (arch/x86/include/asm/paravirt.h:700 arch/x86/mm/fault.c:1479 arch/x86/mm/fault.c:1527) \r\n[70466.635485] ? asm_exc_page_fault (arch/x86/include/asm/idtentry.h:570) \r\n[70466.635793] ? __pfx_init_module (/home/wenqikai/workspace/call_trace/kernel_call_trace.c:7) kernel_call_trace\r\n[70466.635802] ? init_module (/home/wenqikai/workspace/call_trace/kernel_call_trace.c:10) kernel_call_trace\r\n[70466.635806] ? do_one_initcall (init/main.c:1295) \r\n[70466.635870] ? kmalloc_trace (mm/slab_common.c:1065) \r\n[70466.636483] do_init_module (kernel/module/main.c:2463) \r\n[70466.636737] load_module (kernel/module/main.c:2872) \r\n[70466.636740] ? kernel_read_file (fs/kernel_read_file.c:110) \r\n[70466.636965] __do_sys_finit_module (kernel/module/main.c:2972) \r\n[70466.636967] ? __do_sys_finit_module (kernel/module/main.c:2972) \r\n[70466.636972] __x64_sys_finit_module (kernel/module/main.c:2939) \r\n[70466.636974] do_syscall_64 (arch/x86/entry/common.c:50 arch/x86/entry/common.c:80) \r\n[70466.636994] ? irqentry_exit (kernel/entry/common.c:446) \r\n[70466.636997] ? exc_page_fault (arch/x86/mm/fault.c:1531) \r\n[70466.637000] entry_SYSCALL_64_after_hwframe (arch/x86/entry/entry_64.S:120) \r\n[70466.637003] RIP: 0033:0x7ff0b911e69d\r\n./decode_stacktrace.sh: line 225: ./decodecode: No such file or directory\r\n[70466.637009] RSP: 002b:00007fff662d0fc8 EFLAGS: 00000246 ORIG_RAX: 0000000000000139\r\n[70466.637012] RAX: ffffffffffffffda RBX: 0000562af52237b0 RCX: 00007ff0b911e69d\r\n[70466.637013] RDX: 0000000000000000 RSI: 0000562af4eb5cd2 RDI: 0000000000000003\r\n[70466.637015] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000\r\n[70466.637016] R10: 0000000000000003 R11: 0000000000000246 R12: 0000562af4eb5cd2\r\n[70466.637018] R13: 0000562af5223760 R14: 0000562af4eb4888 R15: 0000562af52238d0\r\n[70466.637038]  </TASK>\r\n```\r\n\r\n# 其他\r\n\r\n包查找方法\r\n方法1. sudo aptitude search linux-image-$(uname -r)-dbgsym\r\n\r\n方法2. \t$ apt search linux-image-$(uname -r)\r\n\r\nSorting... Done\r\nFull Text Search... Done\r\nlinux-image-5.4.0-80-generic/focal-updates,focal-security,now 5.4.0-80.90 amd64 [installed,automatic]\r\nSigned kernel image generic\r\n\r\n```\r\n\tlinux-image-5.4.0-80-generic-dbgsym/focal-updates,now 5.4.0-80.90 amd64 [installed]\r\n\t  Signed kernel image generic\r\n\r\n\t$ sudo apt install linux-image-`uname -r`-dbgsym\r\n\r\n```\r\n\r\n# 结束",
      "data": {
        "title": "内核Call Trace调试",
        "date": "2024-04-09 15:43:29",
        "tags": [
          "kernel",
          "debug",
          "gdb"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/nei-he-call-trace-diao-shi.webp",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "nei-he-call-trace-diao-shi"
    },
    {
      "content": "> 欢迎来到我的小站呀，很高兴遇见你！🤝\n\n## 🏠 关于本站\n\n## 👨‍💻 博主是谁\n\n## ⛹ 兴趣爱好\n\n## 📬 联系我呀\n",
      "data": {
        "title": "关于",
        "date": "2019-01-25 19:09:48",
        "tags": [],
        "published": true,
        "hideInList": false,
        "feature": null,
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "",
      "fileName": "about"
    },
    {
      "content": "👏  欢迎使用 **Gridea** ！  \n✍️  **Gridea** 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... \n\n<!-- more -->\n\n[Github](https://github.com/getgridea/gridea)  \n[Gridea 主页](https://gridea.dev/)  \n[示例网站](https://fehey.com/)\n\n## 特性👇\n📝  你可以使用最酷的 **Markdown** 语法，进行快速创作  \n\n🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片  \n\n🏷️  你可以对文章进行标签分组  \n\n📋  你可以自定义菜单，甚至可以创建外部链接菜单  \n\n💻  你可以在 **Windows**，**MacOS** 或 **Linux** 设备上使用此客户端  \n\n🌎  你可以使用 **𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌** 或 **Coding Pages** 向世界展示，未来将支持更多平台  \n\n💬  你可以进行简单的配置，接入 [Gitalk](https://github.com/gitalk/gitalk) 或 [DisqusJS](https://github.com/SukkaW/DisqusJS) 评论系统  \n\n🇬🇧  你可以使用**中文简体**或**英语**  \n\n🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力  \n\n🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步  \n\n🌱 当然 **Gridea** 还很年轻，有很多不足，但请相信，它会不停向前 🏃\n\n未来，它一定会成为你离不开的伙伴\n\n尽情发挥你的才华吧！\n\n😘 Enjoy~\n",
      "data": {
        "title": "Hello Gridea",
        "date": "2018-12-12 00:00:00",
        "tags": [
          "Gridea"
        ],
        "published": true,
        "hideInList": false,
        "feature": "/post-images/hello-gridea.png",
        "isTop": false
      },
      "isEmpty": false,
      "excerpt": "",
      "abstract": "👏  欢迎使用 **Gridea** ！  \n✍️  **Gridea** 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... ",
      "fileName": "hello-gridea"
    }
  ],
  "tags": [
    {
      "name": "timer",
      "slug": "n0CxDupw8",
      "used": true
    },
    {
      "name": "C",
      "slug": "OpCt2xzwzS",
      "used": true
    },
    {
      "name": "openbmc",
      "slug": "6GldNpxoe",
      "used": true
    },
    {
      "name": "coredump",
      "slug": "R47ThOsOa",
      "used": true
    },
    {
      "name": "kernel",
      "slug": "bmbnK_8p9",
      "used": true
    },
    {
      "name": "debug",
      "slug": "yqO2q0D-x4",
      "used": true
    },
    {
      "name": "gdb",
      "slug": "M2VJpWW02p",
      "used": true
    },
    {
      "name": "Gridea",
      "slug": "fQx70FJV7",
      "used": true
    }
  ],
  "menus": [
    {
      "link": "/gridea/",
      "name": "首页",
      "openType": "Internal"
    },
    {
      "link": "/gridea/archives",
      "name": "文章",
      "openType": "Internal"
    },
    {
      "link": "/gridea/tags",
      "name": "标签",
      "openType": "Internal"
    },
    {
      "link": "/gridea/post/about",
      "name": "关于",
      "openType": "Internal"
    }
  ]
}